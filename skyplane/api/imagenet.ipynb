{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.multiprocessing as mp\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import IterableDataset, DataLoader\n",
    "from awsio.python.lib.io.s3.s3dataset import S3IterableDataset\n",
    "\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import io\n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageNetS3(IterableDataset):\n",
    "    def __init__(self, url_list, shuffle_urls=False, transform=None):\n",
    "        self.s3_iter_dataset = S3IterableDataset(url_list,\n",
    "                                                 shuffle_urls)\n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "    def data_generator(self):\n",
    "        try:\n",
    "            while True:\n",
    "                # Based on aplhabetical order of files sequence of label and image will change.\n",
    "                # e.g. for files 0186304.cls 0186304.jpg, 0186304.cls will be fetched first\n",
    "                label_fname, label_fobj = next(self.s3_iter_dataset_iterator)\n",
    "                image_fname, image_fobj = next(self.s3_iter_dataset_iterator)\n",
    "                label = int(label_fobj)\n",
    "                image_np = Image.open(io.BytesIO(image_fobj)).convert('RGB')\n",
    "\n",
    "                # Apply torch visioin transforms if provided\n",
    "                if self.transform is not None:\n",
    "                    image_np = self.transform(image_np)\n",
    "                yield image_np, label\n",
    "\n",
    "        except StopIteration:\n",
    "            return\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.s3_iter_dataset_iterator = iter(self.s3_iter_dataset)\n",
    "        return self.data_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        # compute output\n",
    "        output = model(images)\n",
    "        loss = criterion(output, target)\n",
    "        print(f\"Current loss for batch#{i} is:\")\n",
    "        print(loss.item())\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec68a907bd754fb8a01397d0233fd413",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95fb23a168964e34b7d98d813bf653d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5935d2e67044d2f95d6b413baa87ce3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4557842044224c29a93f06001ccbf44f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# url_list = [\"s3://jason-us-east-1/imagenet-train-000000.tar\"]\n",
    "# Now if we want to transfer our dataset from us-east-1 to us-west-2 since our vm is launched there\n",
    "# We can use Skyplane!!!\n",
    "from skyplane.api.api_class import *\n",
    "client1 = new_client(None)\n",
    "client1.copy(src=\"s3://jason-us-east-1/imagenet-train-000000.tar\", \n",
    "            dst=\"s3://jason-us-west-2/imagenet-train-000000.tar\", recursive=False)\n",
    "url_list = [\"s3://jason-us-west-2/imagenet-train-000000.tar\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "# Torchvision transforms to apply on data\n",
    "preproc = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "dataset = ImageNetS3(url_list, transform=preproc)\n",
    "\n",
    "train_loader = DataLoader(dataset,\n",
    "                        batch_size=batch_size,\n",
    "                        num_workers=2)\n",
    "\n",
    "model = models.__dict__['resnet18'](pretrained=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), 0.1,\n",
    "                            momentum=0.9,\n",
    "                            weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(5):\n",
    "    train(train_loader, model, criterion, optimizer, epoch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, we can back up the model to the cloud, by Skyplane\n",
    "torch.save(model.state_dict(), \"./sample_model.pkl\")\n",
    "client1.copy(src=\"./sample_model.pkl\", \n",
    "            dst=\"s3://jason-us-west-2/\", recursive=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e615813c5489b1590d5f8b2d596a39a5f3baf5ccbb6dde5ecf5546914cc6cb8b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
